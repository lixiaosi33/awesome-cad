# Awesome-cad : A Repository for Paper Reading and Code Sharing

awesome-cad支持以下工作:
- 新潮文章解读，附上链接，博客，代码
- 技巧性强的或有趣工作的代码
- 组会讨论的代码
- 好用工具

------------------------------------
如何将近期Paper Reading和可用代码及其解读添加进仓库
1. fork此项目至用户账号下
2. git clone用户账号的该项目
3. 修改README.md；对于长篇文章解读，新建文件,修改完
4. git add .
5. git commit -m "add new paper"
6. git push origin master
7. 到图形界面下，点击New pull request提交修改

----------------------------------------

注意事项:


1. 代码尽量先在个人账号下存储，对于awesome-cad只提供链接和说明，以及运行注意事项等，保证项目整洁不混乱。
2. 所加内容尽量自己仔细看过
3. 添加内容采用以下规范


* Microsoft (Deep Residual Learning) [[Paper](http://arxiv.org/pdf/1512.03385v1.pdf)][[Slide](http://image-net.org/challenges/talks/ilsvrc2015_deep_residual_learning_kaiminghe.pdf)]
  * Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Deep Residual Learning for Image Recognition, arXiv:1512.03385.
* Microsoft (PReLu/Weight Initialization) [[Paper]](http://arxiv.org/pdf/1502.01852)
  * Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification, arXiv:1502.01852.
* Batch Normalization [[Paper]](http://arxiv.org/pdf/1502.03167)
  * Sergey Ioffe, Christian Szegedy, Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, arXiv:1502.03167.
* GoogLeNet [[Paper]](http://arxiv.org/pdf/1409.4842)
  * Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich, CVPR, 2015.
* VGG-Net [[Web]](http://www.robots.ox.ac.uk/~vgg/research/very_deep/) [[Paper]](http://arxiv.org/pdf/1409.1556)
  * Karen Simonyan and Andrew Zisserman, Very Deep Convolutional Networks for Large-Scale Visual Recognition, ICLR, 2015.
* AlexNet [[Paper]](http://papers.nips.cc/book/advances-in-neural-information-processing-systems-25-2012)
  * Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton, ImageNet Classification with Deep Convolutional Neural Networks, NIPS, 2012.
